{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "data = list(parseDataFromFile('beer_50000.json'))\n",
    "\n",
    "#shuffling data\n",
    "random.shuffle(data)\n",
    "\n",
    "X_train, y_test = train_test_split(data, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "categoryCounts = defaultdict(int)\n",
    "for d in data:\n",
    "    categoryCounts[d['beer/style']] += 1\n",
    "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
    "catID = dict(zip(list(categories),range(len(categories))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Train a logistic regressor using this one-hot encoding to predict whether beers have an ABV greater than 7 percent (i.e., d[’beer/ABV’] > 7). Train the classifier on the training set and report its performance in terms of the accuracy and Balanced Error Rate (BER) on the test set, using a regularization constant of C = 10. For all experiments use the class weight=’balanced’ option (2 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.849\n",
      "Balanced Error Rate:  0.1625314568615568\n"
     ]
    }
   ],
   "source": [
    "#one-hit-encoding\n",
    "one_hot_encoded_catID = []\n",
    "for x in catID:\n",
    "    vector = [0 for y in range(len(catID))]\n",
    "    vector[catID[x]] = 1\n",
    "    one_hot_encoded_catID.append(vector)\n",
    "\n",
    "one_hot_encoded = []\n",
    "true_answer = []\n",
    "for d in X_train:\n",
    "    if d['beer/style'] in categories:\n",
    "        one_hot_encoded.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_answer.append('true')\n",
    "        else:\n",
    "            true_answer.append('false')\n",
    "    else:\n",
    "        vector = [0 for y in range(len(catID))]\n",
    "        one_hot_encoded.append(vector)\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_answer.append('true')\n",
    "        else:\n",
    "            true_answer.append('false')\n",
    "\n",
    "#train model\n",
    "mod = linear_model.LogisticRegression(C=10.0, fit_intercept = True, class_weight='balanced')\n",
    "mod.fit(one_hot_encoded, true_answer)\n",
    "\n",
    "#predict test set\n",
    "one_hot_encoded_test = []\n",
    "for d in y_test:\n",
    "    if d['beer/style'] in categories:\n",
    "        one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "    else:\n",
    "        vector = [0 for y in range(len(catID))]\n",
    "        one_hot_encoded_test.append(vector)\n",
    "predict = mod.predict(one_hot_encoded_test)\n",
    "\n",
    "\n",
    "#true output\n",
    "true_output = []\n",
    "for d in y_test:\n",
    "    if d['beer/ABV'] > 7:\n",
    "        true_output.append('true')\n",
    "    else:\n",
    "        true_output.append('false')\n",
    "        \n",
    "        \n",
    "        \n",
    "#True Positive(TP)\n",
    "TP_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'true'and true_output[i] == 'true':\n",
    "        TP_count = TP_count + 1\n",
    "#True Negative(TN)\n",
    "TN_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'false' and true_output[i] == 'false':\n",
    "        TN_count = TN_count + 1\n",
    "#False Positive(FP)\n",
    "FP_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'true' and true_output[i] == 'false':\n",
    "        FP_count = FP_count + 1\n",
    "#False Negative(TN)\n",
    "FN_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'false' and true_output[i] == 'true':\n",
    "        FN_count = FN_count + 1\n",
    "\n",
    "#Classification Accuracy\n",
    "classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "#Flase Positive Rate(FPR)\n",
    "FPR = FP_count / (FP_count + TN_count)\n",
    "#False Negative Rate(FNR)\n",
    "FNR = FN_count / (FN_count + TP_count)\n",
    "#Balanced Error Rate(BER)\n",
    "BER = (FPR + FNR) / 2\n",
    "print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Extend your model to include two additional features: (1) a vector of five ratings (review/aroma, review/overall, etc.); and (2) the review length (in characters). The length feature should be scaled to be between 0 and 1 by dividing by the maximum length. Using the same value of C from the previous question, report the BER of the new classifier (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appearance = [ d['review/appearance'] for d in X_train]\n",
    "overall = [ d['review/overall'] for d in X_train]\n",
    "aroma = [ d['review/aroma'] for d in X_train]\n",
    "taste = [ d['review/taste'] for d in X_train]\n",
    "palate = [ d['review/palate'] for d in X_train]\n",
    "\n",
    "\n",
    "#review length\n",
    "review_length = [ len(d['review/text']) for d in X_train]\n",
    "#max review length\n",
    "max_length = max(review_length)\n",
    "#normalized\n",
    "norm_review_length = [ d / max_length for d in review_length]\n",
    "\n",
    "\n",
    "additional_feature = []\n",
    "feat_vector = []\n",
    "for i in range(len(X_train)):\n",
    "    feat_vector.append(appearance[i])\n",
    "    feat_vector.append(overall[i])\n",
    "    feat_vector.append(aroma[i])\n",
    "    feat_vector.append(taste[i])\n",
    "    feat_vector.append(palate[i])\n",
    "    feat_vector.append(norm_review_length[i])\n",
    "    additional_feature.append(feat_vector)\n",
    "    feat_vector =[]   \n",
    "\n",
    "#combine feartures\n",
    "new_feature = []\n",
    "for i in range(len(X_train)):\n",
    "    new_feature.append(one_hot_encoded[i] + additional_feature[i])\n",
    "    \n",
    "#train model\n",
    "mod = linear_model.LogisticRegression(C=10.0, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "mod.fit(new_feature, true_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.86004\n",
      "Balanced Error Rate:  0.14569674331617521\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_test = []\n",
    "\n",
    "for d in y_test:\n",
    "    if d['beer/style'] in categories:\n",
    "        one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "    else:\n",
    "        vector = [0 for y in range(len(catID))]\n",
    "        one_hot_encoded_test.append(vector)\n",
    "        \n",
    "        \n",
    "appearance = [ d['review/appearance'] for d in y_test]\n",
    "overall = [ d['review/overall'] for d in y_test]\n",
    "aroma = [ d['review/aroma'] for d in y_test]\n",
    "taste = [ d['review/taste'] for d in y_test]\n",
    "palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "#review length\n",
    "review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "#max review length\n",
    "max_length = max(review_length_test)\n",
    "#normalized\n",
    "norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "additional_feature = []\n",
    "feat_vector = []\n",
    "for i in range(len(X_train)):\n",
    "    feat_vector.append(appearance[i])\n",
    "    feat_vector.append(overall[i])\n",
    "    feat_vector.append(aroma[i])\n",
    "    feat_vector.append(taste[i])\n",
    "    feat_vector.append(palate[i])\n",
    "    feat_vector.append(norm_review_length[i])\n",
    "    additional_feature.append(feat_vector)\n",
    "    feat_vector =[]   \n",
    "\n",
    "#combine feartures\n",
    "new_feature_test = []\n",
    "for i in range(len(y_test)):\n",
    "    new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "    \n",
    "    \n",
    "#predict\n",
    "predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "true_output = []\n",
    "for d in y_test:\n",
    "    if d['beer/ABV'] > 7:\n",
    "        true_output.append('true')\n",
    "    else:\n",
    "        true_output.append('false')\n",
    "        \n",
    "        \n",
    "#True Positive(TP)\n",
    "TP_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'true'and true_output[i] == 'true':\n",
    "        TP_count = TP_count + 1\n",
    "\n",
    "\n",
    "#True Negative(TN)\n",
    "TN_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'false' and true_output[i] == 'false':\n",
    "        TN_count = TN_count + 1\n",
    "\n",
    "\n",
    "#False Positive(FP)\n",
    "FP_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'true' and true_output[i] == 'false':\n",
    "        FP_count = FP_count + 1\n",
    "\n",
    "\n",
    "#False Negative(TN)\n",
    "FN_count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == 'false' and true_output[i] == 'true':\n",
    "        FN_count = FN_count + 1\n",
    "\n",
    "#Classification Accuracy\n",
    "classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "#Flase Positive Rate(FPR)\n",
    "FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "#False Negative Rate(FNR)\n",
    "FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "#Balanced Error Rate(BER)\n",
    "BER = (FPR + FNR) / 2\n",
    "print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement a complete regularization pipeline with the balanced classifier. Split your test data from above in half so that you have 50%/25%/25% train/validation/test fractions. Consider values of C in the range {10^−6, 10^−5, 10^−4, 10^−3}. Report (or plot) the train, validation, and test BER for each value of C. Based on these values, which classifier would you select (in terms of generalization performance) and why (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [d for d in range(len(new_feature_test))]\n",
    "index = random.shuffle(indices)\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "test_indices = indices[:12500]  \n",
    "val_indices = indices[12500:] \n",
    "\n",
    "test_data = [ new_feature_test[i] for i in test_indices]\n",
    "test_true_output = [ true_output[i] for i in test_indices]\n",
    "val_data = [ new_feature_test[i] for i in val_indices]\n",
    "val_true_output = [ true_output[i] for i in val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['false' 'false' 'false' ... 'true' 'true' 'false']\n",
      "classification accuracy:  0.67744\n",
      "Balanced Error Rate:  0.3173496784251614\n",
      "['false' 'false' 'false' ... 'true' 'true' 'false']\n",
      "classification accuracy:  0.67952\n",
      "Balanced Error Rate:  0.3153626595470173\n",
      "['false' 'false' 'false' ... 'true' 'true' 'false']\n",
      "classification accuracy:  0.70184\n",
      "Balanced Error Rate:  0.29397579545249913\n",
      "['false' 'false' 'false' ... 'true' 'true' 'false']\n",
      "classification accuracy:  0.80464\n",
      "Balanced Error Rate:  0.19717741582680248\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(new_feature, true_answer)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "   \n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.67696\n",
      "Balanced Error Rate:  0.31818149161416154\n",
      "classification accuracy:  0.67764\n",
      "Balanced Error Rate:  0.31742726504617924\n",
      "classification accuracy:  0.68784\n",
      "Balanced Error Rate:  0.30759283560239353\n",
      "classification accuracy:  0.76208\n",
      "Balanced Error Rate:  0.2368807976755498\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "    #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(test_data, test_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "  \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "  \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.67736\n",
      "Balanced Error Rate:  0.3180571555835834\n",
      "classification accuracy:  0.67832\n",
      "Balanced Error Rate:  0.3170526972065056\n",
      "classification accuracy:  0.69056\n",
      "Balanced Error Rate:  0.30517658343793774\n",
      "classification accuracy:  0.76704\n",
      "Balanced Error Rate:  0.23239469246012506\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001] \n",
    "for c in c_list:\n",
    "    #train model\n",
    "    mod = linear_model.LogisticRegression(C = c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(val_data, val_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    " \n",
    "\n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "\n",
    "\n",
    "    \n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "            \n",
    "            \n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "\n",
    "            \n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    \n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier which fit 50% train set and 50% true set is better since the accuracy is higher and BER is less when c is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (CSE158 only) An ablation study measures the marginal benefit of various features by re-training the model with one feature ‘ablated’ (i.e., deleted) at a time. Considering each of the three features in your classifier above (i.e., beer style, ratings, and length), report the BER with only the other two features and the third deleted (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove style with training set\n",
    "new_feature_no_style = [ d[13:] for d in new_feature]\n",
    "\n",
    "#remove style with test set\n",
    "test_data_no_style = [ d[13:] for d in test_data]\n",
    "\n",
    "#remove style with val set\n",
    "val_data_no_style = [ d[13:] for d in val_data]\n",
    "\n",
    "\n",
    "#remove length with training set\n",
    "new_feature_no_length = [ d[0:18] for d in new_feature]\n",
    "\n",
    "#remove length with test set\n",
    "test_data_no_length = [ d[0:18] for d in test_data]\n",
    "\n",
    "#remove length with val set\n",
    "val_data_no_length = [ d[0:18] for d in val_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.65504\n",
      "Balanced Error Rate:  0.3398369290926173\n",
      "classification accuracy:  0.6554\n",
      "Balanced Error Rate:  0.3394496324233687\n",
      "classification accuracy:  0.6604\n",
      "Balanced Error Rate:  0.33472216505826424\n",
      "classification accuracy:  0.67424\n",
      "Balanced Error Rate:  0.3222523758482609\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(new_feature_no_style, true_answer)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "   \n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.65544\n",
      "Balanced Error Rate:  0.3393272677855469\n",
      "classification accuracy:  0.65568\n",
      "Balanced Error Rate:  0.33910306929515\n",
      "classification accuracy:  0.65684\n",
      "Balanced Error Rate:  0.3379174453909252\n",
      "classification accuracy:  0.66728\n",
      "Balanced Error Rate:  0.32807981283590737\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(test_data_no_style, test_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "   \n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.65504\n",
      "Balanced Error Rate:  0.33979159670714765\n",
      "classification accuracy:  0.6554\n",
      "Balanced Error Rate:  0.33945529897155235\n",
      "classification accuracy:  0.65676\n",
      "Balanced Error Rate:  0.33813384192565027\n",
      "classification accuracy:  0.67032\n",
      "Balanced Error Rate:  0.32589161833200764\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "    #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(val_data_no_style, val_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "  \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "  \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.67716\n",
      "Balanced Error Rate:  0.3181306566952399\n",
      "classification accuracy:  0.67864\n",
      "Balanced Error Rate:  0.31665743456685336\n",
      "classification accuracy:  0.70048\n",
      "Balanced Error Rate:  0.29557538615869644\n",
      "classification accuracy:  0.80484\n",
      "Balanced Error Rate:  0.19687376793982686\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(new_feature_no_length, true_answer)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        #feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "   \n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.6764\n",
      "Balanced Error Rate:  0.3186649555878015\n",
      "classification accuracy:  0.67712\n",
      "Balanced Error Rate:  0.3179243615384065\n",
      "classification accuracy:  0.68768\n",
      "Balanced Error Rate:  0.3077536343590255\n",
      "classification accuracy:  0.76184\n",
      "Balanced Error Rate:  0.23712199581049775\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(test_data_no_length, test_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        #feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "   \n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy:  0.67784\n",
      "Balanced Error Rate:  0.31751809383185037\n",
      "classification accuracy:  0.67816\n",
      "Balanced Error Rate:  0.3172134959631376\n",
      "classification accuracy:  0.69056\n",
      "Balanced Error Rate:  0.3051935830824889\n",
      "classification accuracy:  0.76484\n",
      "Balanced Error Rate:  0.23432518122872106\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.000001, 0.00001, 0.0001, 0.001]\n",
    "for c in c_list:\n",
    "        #train model\n",
    "    mod = linear_model.LogisticRegression(C=c, fit_intercept = True, class_weight='balanced', max_iter=1000)\n",
    "    mod.fit(val_data_no_length, val_true_output)\n",
    "\n",
    "    one_hot_encoded_test = []\n",
    "\n",
    "    for d in y_test:\n",
    "        if d['beer/style'] in categories:\n",
    "            one_hot_encoded_test.append(one_hot_encoded_catID[catID[d['beer/style']]])\n",
    "        else:\n",
    "            vector = [0 for y in range(len(catID))]\n",
    "            one_hot_encoded_test.append(vector)\n",
    "\n",
    "\n",
    "    appearance = [ d['review/appearance'] for d in y_test]\n",
    "    overall = [ d['review/overall'] for d in y_test]\n",
    "    aroma = [ d['review/aroma'] for d in y_test]\n",
    "    taste = [ d['review/taste'] for d in y_test]\n",
    "    palate = [ d['review/palate'] for d in y_test]\n",
    "\n",
    "\n",
    "    #review length\n",
    "    review_length_test = [ len(d['review/text']) for d in y_test]\n",
    "    #max review length\n",
    "    max_length = max(review_length_test)\n",
    "    #normalized\n",
    "    norm_review_length = [ d / max_length for d in review_length_test]\n",
    "\n",
    "\n",
    "    additional_feature = []\n",
    "    feat_vector = []\n",
    "    for i in range(len(X_train)):\n",
    "        feat_vector.append(appearance[i])\n",
    "        feat_vector.append(overall[i])\n",
    "        feat_vector.append(aroma[i])\n",
    "        feat_vector.append(taste[i])\n",
    "        feat_vector.append(palate[i])\n",
    "        #feat_vector.append(norm_review_length[i])\n",
    "        additional_feature.append(feat_vector)\n",
    "        feat_vector =[]   \n",
    "\n",
    "    #combine feartures\n",
    "    new_feature_test = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        new_feature_test.append(one_hot_encoded_test[i] + additional_feature[i])\n",
    "\n",
    "\n",
    "    #predict\n",
    "    predict = mod.predict(new_feature_test)\n",
    "\n",
    "    true_output = []\n",
    "    for d in y_test:\n",
    "        if d['beer/ABV'] > 7:\n",
    "            true_output.append('true')\n",
    "        else:\n",
    "            true_output.append('false')\n",
    "\n",
    "\n",
    "    #True Positive(TP)\n",
    "    TP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true'and true_output[i] == 'true':\n",
    "            TP_count = TP_count + 1\n",
    "   \n",
    "\n",
    "    #True Negative(TN)\n",
    "    TN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'false':\n",
    "            TN_count = TN_count + 1\n",
    "    \n",
    "\n",
    "    #False Positive(FP)\n",
    "    FP_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'true' and true_output[i] == 'false':\n",
    "            FP_count = FP_count + 1\n",
    "   \n",
    "\n",
    "    #False Negative(TN)\n",
    "    FN_count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if predict[i] == 'false' and true_output[i] == 'true':\n",
    "            FN_count = FN_count + 1\n",
    "\n",
    "\n",
    "    #Classification Accuracy\n",
    "    classification_accuracy = (TP_count + TN_count) / (TP_count + TN_count + FP_count + FN_count)\n",
    "    print('classification accuracy: ', classification_accuracy)\n",
    "\n",
    "    #Flase Positive Rate(FPR)\n",
    "    FPR = FP_count / (FP_count + TN_count)\n",
    "\n",
    "    #False Negative Rate(FNR)\n",
    "    FNR = FN_count / (FN_count + TP_count)\n",
    "\n",
    "    #Balanced Error Rate(BER)\n",
    "    BER = (FPR + FNR) / 2\n",
    "    print('Balanced Error Rate: ', BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
